{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # show progress bar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77.    1.    3.  200.  564.    1.    2.  202.    1.    6.2   2.    4.\n",
      "   3. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 1.        , 0.66666667, 0.43396226, 0.29223744,\n",
       "       0.        , 0.        , 0.57251908, 0.        , 0.32258065,\n",
       "       0.5       , 0.75      , 1.        ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop(\"target\", axis=1), df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(X)\n",
    "print(scaler.data_max_)\n",
    "\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array(X) and dataframe.series(y) to pytorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train.values)\n",
    "y_test = torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size=2, hidden_size=6, return_logits=True):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_last = nn.Linear(hidden_size, output_size)\n",
    "        self.activition = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.return_logits = return_logits\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = self.activition(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activition(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activition(x)\n",
    "        logits = self.fc_last(x)\n",
    "        # if using cross-entropy loss -> output should be logits without softmax\n",
    "        if self.return_logits:\n",
    "            return logits\n",
    "        else:\n",
    "            return self.softmax(logits)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an instance using our defined neural network above, input_size is the number of features from X\n",
    "# since we are outputing the prob. density function from softmax to be able cope with cross-entropy\n",
    "model = MLPClassifier(input_size=X_train.shape[1], return_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using AdamW for back-propagation\n",
    "lr = 0.01 # learning rate\n",
    "n_epochs = 5000 # how many loops for training the data\n",
    "optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss:0.6933416724205017\n",
      "Epoch: 100, loss:0.6903453469276428\n",
      "Epoch: 200, loss:0.6871026754379272\n",
      "Epoch: 300, loss:0.6772035360336304\n",
      "Epoch: 400, loss:0.6357824206352234\n",
      "Epoch: 500, loss:0.5421274900436401\n",
      "Epoch: 600, loss:0.5011302828788757\n",
      "Epoch: 700, loss:0.4828343391418457\n",
      "Epoch: 800, loss:0.4739544987678528\n",
      "Epoch: 900, loss:0.46825891733169556\n",
      "Epoch: 1000, loss:0.4618854522705078\n",
      "Epoch: 1100, loss:0.45619797706604004\n",
      "Epoch: 1200, loss:0.44991886615753174\n",
      "Epoch: 1300, loss:0.44423019886016846\n",
      "Epoch: 1400, loss:0.4392507076263428\n",
      "Epoch: 1500, loss:0.43463385105133057\n",
      "Epoch: 1600, loss:0.43037664890289307\n",
      "Epoch: 1700, loss:0.42676863074302673\n",
      "Epoch: 1800, loss:0.42382940649986267\n",
      "Epoch: 1900, loss:0.4215012788772583\n",
      "Epoch: 2000, loss:0.4194957911968231\n",
      "Epoch: 2100, loss:0.4178418219089508\n",
      "Epoch: 2200, loss:0.4164595901966095\n",
      "Epoch: 2300, loss:0.4152314066886902\n",
      "Epoch: 2400, loss:0.41411730647087097\n",
      "Epoch: 2500, loss:0.4130886197090149\n",
      "Epoch: 2600, loss:0.41216880083084106\n",
      "Epoch: 2700, loss:0.41128844022750854\n",
      "Epoch: 2800, loss:0.4104762375354767\n",
      "Epoch: 2900, loss:0.40977054834365845\n",
      "Epoch: 3000, loss:0.40895840525627136\n",
      "Epoch: 3100, loss:0.4077839255332947\n",
      "Epoch: 3200, loss:0.4068283140659332\n",
      "Epoch: 3300, loss:0.40606489777565\n",
      "Epoch: 3400, loss:0.4043262004852295\n",
      "Epoch: 3500, loss:0.4025667905807495\n",
      "Epoch: 3600, loss:0.400712251663208\n",
      "Epoch: 3700, loss:0.3999362885951996\n",
      "Epoch: 3800, loss:0.39939284324645996\n",
      "Epoch: 3900, loss:0.39895105361938477\n",
      "Epoch: 4000, loss:0.3985765278339386\n",
      "Epoch: 4100, loss:0.3982502520084381\n",
      "Epoch: 4200, loss:0.3979669213294983\n",
      "Epoch: 4300, loss:0.3977208733558655\n",
      "Epoch: 4400, loss:0.3975026309490204\n",
      "Epoch: 4500, loss:0.3973093628883362\n",
      "Epoch: 4600, loss:0.3971363306045532\n",
      "Epoch: 4700, loss:0.39698249101638794\n",
      "Epoch: 4800, loss:0.3968445360660553\n",
      "Epoch: 4900, loss:0.3967181146144867\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad() # reset gradient storage for the optimizer, has to be done in before every BP\n",
    "    outputs = model(X_train) # passing the X_train through the whole network and get output\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print stats on the fly\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss:{loss.item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7f95753002cc6287146cdd2b0bddab10ec1167f14806726ba1a93cfc6eb7ce3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
